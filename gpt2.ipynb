{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMh87cyU6xAyLzPANPYfm+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timschott/gpt-2/blob/master/gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeOtICLsYJel",
        "colab_type": "text"
      },
      "source": [
        "Going to use https://www.gwern.net/GPT-2 to implement GPT-2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9lZOa-UXqig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bcf7aa3e-a1b2-4888-c160-3fbee91c88c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ16fj7-XP_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9b68126a-2e9a-429f-8ad3-a49bd470fa9f"
      },
      "source": [
        " ## Clean up then Clone the repo\n",
        "#%pwd\n",
        "## %cd /content\n",
        "#%cd ..\n",
        "!git clone https://github.com/timschott/gpt-2\n",
        "# %cd ../\n",
        "#%cd ..\n",
        "#%rm -rf gpt-2/\n",
        "#%ls\n",
        "#%cd gpt-2/\n",
        "#%ls\n",
        "## can git pull!\n",
        "#!git pull\n",
        "## %rm -rf data/ginsburg-lines-v001.txt.npz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 529, done.\u001b[K\n",
            "remote: Total 529 (delta 0), reused 0 (delta 0), pack-reused 529\u001b[K\n",
            "Receiving objects: 100% (529/529), 4.44 MiB | 6.20 MiB/s, done.\n",
            "Resolving deltas: 100% (313/313), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95BdSog6X0xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "975282b8-a94a-4238-d66e-94c2b84bdb6d"
      },
      "source": [
        "## Install stuff\n",
        "%tensorflow_version 1.x\n",
        "## !python --version\n",
        "## Kind of nice that all this stuff is already installed. \n",
        "## !pip list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMFmMZHfY2x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## make sure we have a gpu running\n",
        "## Navigate to Edit→Notebook Settings\n",
        "## select GPU from the Hardware Accelerator drop-down\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EEDURppbTqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2845d273-099c-4745-b712-a2fda43d6b9b"
      },
      "source": [
        "# make sure we are mounted correctly\n",
        "!ls\n",
        "## cd\n",
        "%cd gpt-2/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gpt-2  sample_data\n",
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2m7AP4Kbt7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "79acccf1-f883-47bf-9e6d-e03e62b02540"
      },
      "source": [
        "## download the stock model (perhaps move it inside gpt-2 if you're not inside git repo)\n",
        "!python3 download_model.py 117M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 1.10Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 61.3Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.02Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:06, 75.0Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.87Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 55.8Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 55.3Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjH9sBqPczk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## make a data container\n",
        "!mkdir ../data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwp_kaLHjLA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2831e5a1-ce7d-464a-c4c0-019a2d986680"
      },
      "source": [
        "#!cd gpt-2/\n",
        "# for some reason need this percent sign\n",
        "# %cd gpt-2/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  download_model.py  \u001b[0m\u001b[01;34mmodels\u001b[0m/           train-horovod.py\n",
            "DEVELOPERS.md    \u001b[01;32mencode.py\u001b[0m*         README.md         \u001b[01;32mtrain.py\u001b[0m*\n",
            "Dockerfile.cpu   __init__.py        requirements.txt\n",
            "Dockerfile.gpu   LICENSE            \u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNML44vpEtxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cat ../drive/My\\ Drive/sents/opinions_all.txt | head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM4gss4QdxW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6a1171ae-a7aa-448f-84c9-1c3c6e8e40b6"
      },
      "source": [
        "## encode the sentences into the expected format\n",
        "\n",
        "# % cd gpt-2/\n",
        "# !git pull\n",
        "\n",
        "!PYTHONPATH=src ./encode.py ../drive/My\\ Drive/sents/opinions_all.txt ../data/opinions-lines-v001.txt.npz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-16 19:40:33.168176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Reading files\n",
            "100% 1/1 [00:19<00:00, 19.09s/it]\n",
            "Writing ../data/opinions-lines-v001.txt.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgZ0aHQuf2Vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "a7abd395-7471-43d9-df70-5599f076aef5"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "!pip install toposort\n",
        "!pip install hparams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Installing collected packages: toposort\n",
            "Successfully installed toposort-1.5\n",
            "Collecting hparams\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ec/bcc7011ec23390ac0ccafd031ad9f850430390b4ed3a8b1550788b7fe586/hparams-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from hparams) (2.7.1)\n",
            "Installing collected packages: hparams\n",
            "Successfully installed hparams-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rqlU5NXsBix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls -ll\n",
        "#!chmod +x train.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLqt_C57SNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -rf checkpoint\n",
        "%rm -rf samples/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNPrlZvyfVT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get latest code and fine tune\n",
        "!git pull\n",
        "\n",
        "## fine tune the model\n",
        "## going to run for a shorter amount of time. i don't want the loss to drop below like 2. \n",
        "!PYTHONPATH=src ./train.py --model_name 117M --dataset ../data/opinions-lines-v001.txt.npz \\\n",
        "--batch_size 2 --save_every 100 --sample_every 100 \\\n",
        "--learning_rate=.003 --run_name scalia_1 --top_p .9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yghwo9LppE2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f35295a3-4af2-4403-e846-cc2c88e7f8d3"
      },
      "source": [
        "ls checkpoint/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mscalia_1\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHJSPoVApJPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir ../drive/My\\ Drive/sbotus_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOb9hoe2pU7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr checkpoint/ ../drive/My\\ Drive/sbotus_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isLi7sBdpxlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr ../data/ ../drive/My\\ Drive/sbotus_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll7k4cO8qEl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr models/117M/ ../drive/My\\ Drive/sbotus_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGq2eNwdTMn",
        "colab_type": "text"
      },
      "source": [
        "Post model genration and saving, I am going to load my model from storage and run some text generation scripts with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEIhCu2zdfUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## reclone the repo.\n",
        "!git clone https://github.com/timschott/gpt-2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neFeo4xrd1x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## make a models directory to put it in. \n",
        "## %cd gpt-2\n",
        "## make a\n",
        "%mkdir models"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNewukOMeHyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## reverse the cp's \n",
        "%cp -avr ../drive/My\\ Drive/sbotus_output_two/117M models/117M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHaiMMPZesUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr ../drive/My\\ Drive/sbotus_output_two/checkpoint/scalia_1 models/all_justices_1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X6Dd3wxf-9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## copy over json / param files from base model to custom (cf https://www.gwern.net/GPT-2#gpt-2-poetry-samples)\n",
        "%cp models/117M/encoder.json models/all_justices_1/\n",
        "%cp models/117M/hparams.json models/all_justices_1/\n",
        "%cp models/117M/vocab.bpe models/all_justices_1/\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNqGf01ugjPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## first install fire module.\n",
        "## !pip install fire \n",
        "\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sKW90uxNS0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir ../data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvVwdwe_iOEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## cook it up\n",
        "!python src/generate_unconditional_samples.py --top_k 40 --temperature 0.9 --nsamples 100 \\\n",
        "--seed 2 --model_name all_justices_1 --top_p 0.9 > ../data/one_hundred_samples.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K2cbzhbrDvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir ../drive/My\\ Drive/sbotus_output_two"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrYUvH0IrXY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr checkpoint/ ../drive/My\\ Drive/sbotus_output_two"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYYfbGswrs1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3037c4dc-94f1-4023-f810-6334419d3c40"
      },
      "source": [
        "%cp -avr ../data/ ../drive/My\\ Drive/sbotus_output_two"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'../data/' -> '../drive/My Drive/sbotus_output_two/data'\n",
            "'../data/opinions-lines-v001.txt.npz' -> '../drive/My Drive/sbotus_output_two/data/opinions-lines-v001.txt.npz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQlmQ43rvp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -avr models/117M/ ../drive/My\\ Drive/sbotus_output_two"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}